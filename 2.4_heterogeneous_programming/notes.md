CUDA programming model also assumes that both the host and the device maintain their own separate memory spaces in DRAM, referred to as host memory and device memory, respectively. 

and Unified memory provides managed memory to bridge both memory spaces. Accesible from both CPUs and GPUs with same common address space.